{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a97a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1aa6972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "0    29822\n",
       "1     2275\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"../../data/clean/encoded/HealthInspectionsEncoded.csv\")\n",
    "df[\"failFlag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0de52",
   "metadata": {},
   "source": [
    "## Split into Training, Test and Val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b122ea33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "0    15576\n",
       "1     1333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"inspection_date\"] = pd.to_datetime(\n",
    "    dict(year=df[\"insp_year\"], month=df[\"insp_month\"], day=df[\"insp_day\"])\n",
    ")\n",
    "train_mask = df[\"inspection_date\"] <= \"2023-12-31\"\n",
    "val_mask   = (df[\"inspection_date\"] >= \"2024-01-01\") & (df[\"inspection_date\"] <= \"2024-12-31\")\n",
    "test_mask  = df[\"inspection_date\"] >= \"2025-01-01\"\n",
    "\n",
    "\n",
    "train_df = df[train_mask].copy()\n",
    "val_df   = df[val_mask].copy()\n",
    "test_df  = df[test_mask].copy()\n",
    "train_df=train_df.drop(columns=[\"inspection_date\"])\n",
    "val_df=val_df.drop(columns=[\"inspection_date\"])\n",
    "test_df=test_df.drop(columns=[\"inspection_date\"])\n",
    "# print(test_df.columns)\n",
    "train_df.to_csv(\"../../data/clean/train/HealthInspectionTrain.csv\",index=False)\n",
    "test_df.to_csv(\"../../data/clean/test/HealthInspectionTest.csv\",index=False)\n",
    "val_df.to_csv(\"../../data/clean/val/HealthInspectionVal.csv\",index=False)\n",
    "train_df['failFlag'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8789cf",
   "metadata": {},
   "source": [
    "## Using GAN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ac52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"failFlag\"\n",
    "\n",
    "\n",
    "X = train_df.drop(columns=[label_col]).values   \n",
    "y = df[label_col].values.astype(np.float32) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "data = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "labels = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "input_dim = data.shape[1]        \n",
    "latent_dim = 20  #noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a7ff14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.Tanh(),           # matches [-1, 1] scaling\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 1),   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "generator = Generator(latent_dim, input_dim)\n",
    "discriminator = Discriminator(input_dim)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()         \n",
    "lr = 2e-4\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af4d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300 | D: 1.3465 | G: 0.7322\n",
      "Epoch 100/300 | D: 1.4222 | G: 0.6874\n",
      "Epoch 150/300 | D: 1.3627 | G: 0.7236\n",
      "Epoch 200/300 | D: 1.2031 | G: 0.8764\n",
      "Epoch 250/300 | D: 1.2004 | G: 1.0960\n",
      "Epoch 300/300 | D: 1.0484 | G: 0.9230\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for _ in range(len(data) // batch_size):\n",
    "       \n",
    "        optimizer_d.zero_grad()#start with dis\n",
    "\n",
    "        idx = torch.randint(len(data), (batch_size,))\n",
    "        real_data = data[idx]\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        fake_data = generator(z).detach()\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "        out_real = discriminator(real_data)\n",
    "        out_fake = discriminator(fake_data)\n",
    "\n",
    "        loss_real = criterion(out_real, real_labels)\n",
    "        loss_fake = criterion(out_fake, fake_labels)\n",
    "        d_loss = loss_real + loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        \n",
    "        optimizer_g.zero_grad() #end with gen\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        fake_data = generator(z)\n",
    "        out_fake = discriminator(fake_data)\n",
    "\n",
    "        g_loss = criterion(out_fake, real_labels)  \n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | D: {d_loss.item():.4f} | G: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73dde762",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_synth = 9000\n",
    "z = torch.randn(n_synth, latent_dim)\n",
    "synth_scaled = generator(z).detach().cpu().numpy()\n",
    "\n",
    "synth_X = scaler.inverse_transform(synth_scaled)\n",
    "\n",
    "synth_df = pd.DataFrame(synth_X, columns=train_df.drop(columns=[label_col]).columns)\n",
    "\n",
    "synth_df[label_col] = 1.0\n",
    "\n",
    "synth_df.to_csv(\"../../data/clean/HealthInspectionGANSynthetic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9be09ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "1.0    9000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_syn=pd.read_csv(\"../../data/clean/HealthInspectionsynthetic.csv\")\n",
    "df_syn[\"failFlag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf726c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are inspection type feature with continuos number check if this might imporove the model?\n",
    "\n",
    "# cat_cols = [c for c in synth_df.columns if c.startswith(\"inspection_type_clean_\")]\n",
    "\n",
    "# def collapse_one_hot(row):\n",
    "#     vals = row[cat_cols].values.astype(float)\n",
    "#     idx = np.argmax(vals)             # position of max logit\n",
    "#     one_hot = np.zeros_like(vals)\n",
    "#     one_hot[idx] = 1.0\n",
    "#     row[cat_cols] = one_hot\n",
    "#     return row\n",
    "\n",
    "# df_syn = synth_df.apply(collapse_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "795133a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "0.0    15576\n",
       "1.0    10333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([train_df, df_syn], ignore_index=True)\n",
    "df_balanced.to_csv(\"../../data/clean/train/HealthInspectionGANTrain.csv\", index=False)\n",
    "df_balanced[\"failFlag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e044",
   "metadata": {},
   "source": [
    "## Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a440aee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "0    15576\n",
       "1     1333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smote = train_df.copy()\n",
    "# print(df_smote.columns)\n",
    "\n",
    "label_col = \"failFlag\"\n",
    "df_smote[\"failFlag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfc8b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_smote.drop(columns=[label_col])\n",
    "y = df_smote[label_col].values\n",
    "\n",
    "\n",
    "cat_names = (\n",
    "    [\"BusinessName_id\", \"Address_id\", \"insp_year\", \"insp_month\", \"insp_day\", \"insp_dow\"]\n",
    "    + [c for c in X.columns if c.startswith(\"inspection_type_clean_\")]\n",
    ")\n",
    "\n",
    "cat_indices = [X.columns.get_loc(c) for c in cat_names]\n",
    "\n",
    "sm = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X.values, y)\n",
    "\n",
    "# back to DataFrame\n",
    "train_smote = pd.DataFrame(X_res, columns=X.columns)\n",
    "train_smote[label_col] = y_res\n",
    "train_smote.to_csv(\"../../data/clean/train/HealthInspectionSMOTETrain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1787c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failFlag\n",
       "0    15576\n",
       "1    15576\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_smote[\"failFlag\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0245a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
