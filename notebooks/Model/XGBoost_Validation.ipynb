{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model Validation\n",
    "## Validation on Real-World Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:03:32.624433Z",
     "start_time": "2026-01-02T01:03:32.441143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:03:47.135250Z",
     "start_time": "2026-01-02T01:03:47.082539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING VALIDATION DATA\n",
      "======================================================================\n",
      "\n",
      "Validation data: (6041, 38)\n",
      "\n",
      "Removing violation_count (data leakage)\n",
      "Removed! New shape: (6041, 37)\n",
      "\n",
      "X_val: (6041, 36)\n",
      "y_val: (6041,)\n",
      "\n",
      "Target distribution:\n",
      "  Pass (0): 5,672 (93.9%)\n",
      "  Fail (1): 369 (6.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING VALIDATION DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load validation data\n",
    "val_df = pd.read_csv('/Users/deepaktalwar/PyCharmMiscProject/HealthInspectionTest.csv')\n",
    "\n",
    "print(f\"\\nValidation data: {val_df.shape}\")\n",
    "\n",
    "# Remove violation_count if present\n",
    "if 'violation_count' in val_df.columns:\n",
    "    print(f\"\\nRemoving violation_count (data leakage)\")\n",
    "    val_df = val_df.drop('violation_count', axis=1)\n",
    "    print(f\"Removed! New shape: {val_df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X_val = val_df.drop('failFlag', axis=1)\n",
    "y_val = val_df['failFlag']\n",
    "\n",
    "print(f\"\\nX_val: {X_val.shape}\")\n",
    "print(f\"y_val: {y_val.shape}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Pass (0): {(y_val==0).sum():,} ({(y_val==0).sum()/len(y_val)*100:.1f}%)\")\n",
    "print(f\"  Fail (1): {(y_val==1).sum():,} ({(y_val==1).sum()/len(y_val)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:04:03.340713Z",
     "start_time": "2026-01-02T01:04:03.148176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING TRAINED MODEL\n",
      "======================================================================\n",
      "\n",
      "Model loaded: XGBoost (Tuned with scale_pos_weight)\n",
      "  Features: 36\n",
      "  scale_pos_weight: 13.1082\n",
      "\n",
      "Training Performance:\n",
      "  cv_roc_auc: 0.8007\n",
      "  baseline_roc_auc: 0.8089\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING TRAINED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load model\n",
    "model_package = joblib.load('/Users/deepaktalwar/PyCharmMiscProject/outputs2/xgboost_tuned_scaleweight.pkl')\n",
    "\n",
    "model = model_package['model']\n",
    "scaler = model_package['scaler']\n",
    "feature_names = model_package['feature_names']\n",
    "\n",
    "print(f\"\\nModel loaded: {model_package['model_name']}\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  scale_pos_weight: {model_package['scale_pos_weight']:.4f}\")\n",
    "\n",
    "if 'training_performance' in model_package:\n",
    "    print(f\"\\nTraining Performance:\")\n",
    "    for metric, value in model_package['training_performance'].items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:04:13.204538Z",
     "start_time": "2026-01-02T01:04:13.185584Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reorder columns to match training\n",
    "X_val_ordered = X_val[feature_names]\n",
    "\n",
    "# Scale features\n",
    "X_val_scaled = scaler.transform(X_val_ordered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:04:24.694762Z",
     "start_time": "2026-01-02T01:04:24.666614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MAKING PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "Predictions made\n",
      "\n",
      "Prediction probability stats:\n",
      "  Min:  0.0012\n",
      "  Max:  0.9690\n",
      "  Mean: 0.2625\n",
      "\n",
      "Predictions > 0.5: 1,058\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nPredictions made\")\n",
    "print(f\"\\nPrediction probability stats:\")\n",
    "print(f\"  Min:  {y_pred_proba.min():.4f}\")\n",
    "print(f\"  Max:  {y_pred_proba.max():.4f}\")\n",
    "print(f\"  Mean: {y_pred_proba.mean():.4f}\")\n",
    "print(f\"\\nPredictions > 0.5: {(y_pred_proba > 0.5).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:05:10.675628Z",
     "start_time": "2026-01-02T01:05:10.653289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "Metrics:\n",
      "  ROC-AUC:        0.9385\n",
      "  Accuracy:       0.8684\n",
      "  Precision:      0.2987\n",
      "  Recall:         0.8564\n",
      "  F1-Score:       0.4429\n",
      "  Avg Precision:  0.5479\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  ROC-AUC:        {roc_auc:.4f}\")\n",
    "print(f\"  Accuracy:       {accuracy:.4f}\")\n",
    "print(f\"  Precision:      {precision:.4f}\")\n",
    "print(f\"  Recall:         {recall:.4f}\")\n",
    "print(f\"  F1-Score:       {f1:.4f}\")\n",
    "print(f\"  Avg Precision:  {avg_precision:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:05:19.956541Z",
     "start_time": "2026-01-02T01:05:19.932530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT\n",
      "======================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Pass       0.99      0.87      0.93      5672\n",
      "        Fail       0.30      0.86      0.44       369\n",
      "\n",
      "    accuracy                           0.87      6041\n",
      "   macro avg       0.64      0.86      0.68      6041\n",
      "weighted avg       0.95      0.87      0.90      6041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(classification_report(y_val, y_pred, target_names=['Pass', 'Fail']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:05:38.372315Z",
     "start_time": "2026-01-02T01:05:38.341973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX\n",
      "======================================================================\n",
      "\n",
      "              Predicted\n",
      "           Pass    Fail\n",
      "Pass       4930   742   \n",
      "Fail       53     316   \n",
      "\n",
      "Key Insights:\n",
      "  Correctly caught: 316/369 failures (85.6%)\n",
      "  Missed: 53 failures (14.4%)\n",
      "  False alarms: 742 (unnecessary inspections)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(f\"\\n              Predicted\")\n",
    "print(f\"           Pass    Fail\")\n",
    "print(f\"Pass       {cm[0,0]:<6} {cm[0,1]:<6}\")\n",
    "print(f\"Fail       {cm[1,0]:<6} {cm[1,1]:<6}\")\n",
    "\n",
    "# Key insights\n",
    "total_failures = cm[1,0] + cm[1,1]\n",
    "caught = cm[1,1]\n",
    "missed = cm[1,0]\n",
    "false_alarms = cm[0,1]\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"  Correctly caught: {caught}/{total_failures} failures ({recall*100:.1f}%)\")\n",
    "print(f\"  Missed: {missed} failures ({missed/total_failures*100:.1f}%)\")\n",
    "print(f\"  False alarms: {false_alarms} (unnecessary inspections)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
